summary(regrline)
bye()
swirl()
fit<-lm(child~parent, galton)
summary(fit)
mean(fit$residuals)
cov(fit$residuals, galton$parent)
library(ggplot2)
x <- c(0.8, 0.47, 0.51, 0.73, 0.36, 0.58, 0.57, 0.85, 0.44, 0.42)
y <- c(1.39, 0.72, 1.55, 0.48, 1.19, -1.59, 1.23, -0.65, 1.49, 0.05)
lm(y~x)
library(ggplot2)
df<-data.frame(x,y)
g<-ggplot(df, aes(x=x,y=y))
g<-g+geom_point(size=7,colour='black', alpha=.2)
g<-g+geom_point(size=4, colour='red', alpha=.7)
g<-g+geom_smooth(method= 'lm', colour='green')
g
x <- c(0.61, 0.93, 0.83, 0.35, 0.54, 0.16, 0.91, 0.62, 0.62)
y <- c(0.67, 0.84, 0.6, 0.18, 0.85, 0.47, 1.1, 0.65, 0.36)
fit<-lm(y~x)
plot(fit)
pvalue<-1-pf(f.stat["value"], f.stat["numdf"],f.stat["dendf"])
f.stat<-summary(fit)$fstatistic
pvalue<-1-pf(f.stat["value"], f.stat["numdf"],f.stat["dendf"])
summary(fit)
x <- mtcars$wt
y <- mtcars$mpg
fit2 <- lm(y ~ x)
coef <- summary(fit2)$coefficients
newdata <- data.frame(x=c(mean(x)))
p1 <- predict(fit2, newdata, interval = ("confidence"))
print(p1)
#question 9
x <- mtcars$wt
y <- mtcars$mpg
fit2 <- lm(y ~ x)
fit3<- lm(y~x-1)
coef2 <- summary(fit2)$coefficients
coef3 <- summary(fit3)$coefficients
coef2 <- summary(fit2)$coefficients
coef3 <- summary(fit3)$coefficients
ssx2<-sum(resid(fit2)^2)
ssx3<-sum(resid(fit3)^2)
ssx3/ssx2
coef3
summary(fit3)
sum(y-mean(y)^2)/ssx2
ssx2<-sum(resid(fit2)^2)
ssx2/sum((y-mean(y))^2)
swirl()
LIBRARY(SWIRL)
library(swirl)
swirl()
fit<-lm(child~parent, galton)
summary(fit)
mean(fit$residuals)
cov(fit$residuals, galton$parent)
ols.ic<-fit$coef[1]
ols.slope<-fit$coef[2]
rhs-lhs
lhs-rhs
all.equal(lhs,rhs)
varChil<-var(galton$child)
varChild<-var(galton$child)
varRes<-var(fit$residuals)
varEst<-var(est())
varEst<-var(est(ols.slope, ols.ic))
all.equal(varChild,varRes+varEst)
efit <- lm(accel ~ mag+dist, attenu)
mean(res(efit))
mean(resid(efit))
mean(residuals(efit))
mean(efit$residuals)
cov(efit$residuals,attenu$mag)
cov(efit$residuals,attenu$dist)
cor(gpa_nor, gch_nor)
l_nor<-lm(gpa_nor~gch_nor)
l_nor<-lm(gch_nor~gpa_nor)
fit<-lm(child~parent, galton)
sqrt(sum(resid$fit)^2/(n-2))
sqrt(sum(residuals$fit)^2/(n-2))
sqrt(sum(residuals(fit)^2/(n-2))
)
sqrt(sum(fit$residuals^2)/(n-2))
summary(fit)$sigma
sqrt(deviance(fit)/(n-2))
mu<-mean(galton$child)
sTot<-sum(galton$child-mu)^2
sTot<-sum((galton$child-mu)^2)
sRes<-deviance(galton$child)
sRes<-deviance(fit
)
1-sRes/sTot
summary(fit)$r.squared
cor(galton$child, galton$parent)^2
ones<-rep(1, nrow(galton))
lm(child ~ ones + parent -1, galton)
lm(child ~ parent, galton)
lm(child ~ 1, galton)
head(trees)
fit<lm(Volume ~ Girth + Height + Constant -1, trees)
fit<-lm(Volume ~ Girth + Height + Constant -1, trees)
trees2<-eliminate("Girth", trees)
head(trees2)
fit2<-lm(Volume ~ Height + Constant -1, trees2)
lapply(list(fit,fit2), coef)
?str
str(mtcars)
scatterplot.matrix(~. , data=mtcars, main= "Matrix plot: Paired Relationships")
install.packages("car")
library (car)
scatterplot.matrix(~. , data=mtcars, main= "Matrix plot: Paired Relationships")
library(car)
library("car", lib.loc="~/R/win-library/3.2")
install.packages(c("ggplot2", "Hmisc", "rmarkdown"))
install.packages(c("ggplot2", "Hmisc", "rmarkdown"))
install.packages(c("ggplot2", "Hmisc", "rmarkdown"))
library("car", lib.loc="~/R/win-library/3.2")
remove.packages("car", lib="~/R/win-library/3.2")
install.packages("car")
library(car)
scatterplot.matrix(~. , data=mtcars, main= "Matrix plot: Paired Relationships")
scatterplot.matrix(~mpg + cyl + disp + hp + drat + wt + qsec + vs + am + gear +
carb , data=mtcars, main= "Matrix plot: Paired Relationships")
boxplot(mpg~am , data=mtcars, main= "Boxplot: MPG vs AM")
cor(mpg, am)
cor(mtcars$mpg, mtcars$am)
render("Assignment.Rmd", "pdf_document")
rmarkdown::render("Assignment.Rmd", "pdf_document")
rmarkdown::render("D:\Documents\Data Science\Courses\Data Scientist Specialization (JOHN HOPKINS)\7. Regression\Assignment.Rmd", "pdf_document")
rmarkdown::render("D:/Documents/Data Science/Courses/Data Scientist Specialization (JOHN HOPKINS)/7. Regression/Assignment.Rmd", "pdf_document")
rmarkdown::render("D:/Documents/Data Science/Courses/Data Scientist Specialization (JOHN HOPKINS)/7. Regression/Assignment.Rmd", "pdf_document")
rmarkdown::render("D:/Documents/Data Science/Courses/Data Scientist Specialization (JOHN HOPKINS)/7. Regression/Assignment.Rmd", "pdf_document")
rmarkdown::render("D:/Documents/Data Science/Courses/Data Scientist Specialization (JOHN HOPKINS)/7. Regression/Assignment.Rmd", "pdf_document")
install.packages("markdown")
plot(best_model)
par(mfrow=c(2,2))
plot(best_model)
mean(subset(mtcars, mtcars$am=="Automatic")$mpg
par(mfrow = c(2, 2))
lm(mpg ~ am, data = mtcars)$r.squared
lm(mpg ~ am, data = mtcars)
summary(lm(mpg ~ am, data = mtcars))$r.squared
c(mean(subset(mtcars, mtcars$am=="Automatic")$mpg),
mean(subset(mtcars, mtcars$am=="Manual")$mpg))
c(p-value=t.test(mpg ~ am, data = mtcars)$p.value,
r.squared=summary(lm(mpg ~ am, data = mtcars))$r.squared)
c("p-value"=t.test(mpg ~ am, data = mtcars)$p.value,
"r.squared"=summary(lm(mpg ~ am, data = mtcars))$r.squared)
anova(best_model, am_only_model)$coef
model<-lm(mpg ~ ., data= mtcars)
best_model<-step(model, direction="both", trace=0)
summary(best_model)$call;summary(best_model)$adj.r.squared
```
The outcome shows that the best regression model uses `cyl`, `wt`, `hp` and `am` as relevant variables. According to the `summary`, **84% of the variability of  mpg is explained by this model**.
#### b. ANOVA
Now lets compare the 2 models. ANOVA will help us determine if the confounder variables are relevant to the model fitting or not:
```{r}
am_only_model<-lm(mpg ~ am, data= mtcars)
anova(best_model, am_only_model)$table
```
anova(best_model, am_only_model)
anova(best_model, am_only_model)$p.value
anova(best_model, am_only_model)$F
anova(best_model, am_only_model)$$"Pr(>F)"[2]
anova(best_model, am_only_model)$"Pr(>F)"[2]
data(mtcars)
str(mtcars)
mtcars$cyl<-factor(mtcars$cyl)
mtcars$cyl<-factor(mtcars$cyl)
fit<-(mpg~cyl+wt, data=mtcars)
fit<-lm(mpg~cyl+wt, data=mtcars)
fit
fit1<-lm(mpg~cyl, data=mtcars)
anova(fit1, fit)
fit1
fit_adjuste_int<-lm(mpg~cyl+wt+cyl:wt, data=mtcars)
data(mtcars)
fit_adjusted<-lm(mpg~cyl+wt, data=mtcars)
fit_adjuste_int<-lm(mpg~cyl+wt+cyl:wt, data=mtcars)
anova(fit_adjusted, fit_adjuste_int)
anova(fit_adjusted, fit_adjuste_int)$Pr
fit <- lm(y ~ x)
max(hatvalues(fit))
x <- c(0.586, 0.166, -0.042, -0.614, 11.72)
y <- c(0.549, -0.026, -0.127, -0.751, 1.344)
fit <- lm(y ~ x)
max(hatvalues(fit))
x <- c(0.586, 0.166, -0.042, -0.614, 11.72)
y <- c(0.549, -0.026, -0.127, -0.751, 1.344)
fit <- lm(y ~ x)
dfbetas(fit)
library(swirl)
swirl()
lm(Fertility~., data=swiss)
all<_lm(Fertility~., data=swiss)
all<-lm(Fertility~., data=swiss)
summary(all)
lm(Fertility~Agriculture, data=swiss)
summary(lm(Fertility~Agriculture, data=swiss))
cor(Examination, Education)
cor(swiss$Examination, swiss$Education)
cor(swiss$Agriculture, swiss$Education)
makelms(swiss)
makelms()
ec<-swiss$Examination+swiss$Catholic
efit<-lm(Fertility~.+ec, swiss)
all$coefficients-efit$coefficients
6
dim(InsectSprays)
head(InsectSprays)
head(InsectSprays,15)
sB
summary(InsectSprays[,2])
sapply(InsectSprays)
sapply(InsectSprays, FUN=class())
sapply(InsectSprays, FUN=class(col(InsectSprays)))
sapply(InsectSprays,class)
fit<-lm(count~spray, swiss)
fit<-lm(count~spray, data=InsectSprays)
summary(fit)
summary(fit)$coef
est<-summary(fit)$coef[,1]
mean(InsectSprays$count(sprayA))
mean(InsectSprays$count==sprayA)
mean(InsectSprays$count==A)
mean(InsectSprays$count=="A")
mean(sA)
mean(sB)
nfit<-lm(count~spray-1, InsectSprays)
summary(nfit)
summary(nfit)$coef
spray2<- relevel(spray, "C")
spray2<- relevel(InsectSprays$spray, "C")
fit2<-lm(count~spray, InsectSprays)
fit2<-lm(count~spray2, InsectSprays)
summary(fit2)$coef
mean(sC)
(fit$coef[2]-fit$coef[3])/1.6011
dim(WHO)
dim(hunger)
948
names(hunger)
fit<-lm(X~., hunger)
fit<-lm(Numeric~Year, hunger)
summary(fit)$coef
summary(lm(Numeric~x[hunger$sex=="Female"], hunger))$coef
lmF<-lm(Numeric~Year[hunger$sex=="Female"], hunger)
lmF<-lm(Numeric[hunger$sex=="Female"]~Year[hunger$sex=="Female"], hunger)
lmF<-lm(Numeric[hunger$Sex=="Female"]~Year[hunger$Sex=="Female"], hunger)
lmM<-lm(Numeric[hunger$Sex=="Male"]~Year[hunger$Sex=="Male"], hunger)
lmBoth<-lm(Numeric~Year+Sex, hunger)
summary(lmBoth)$coef
summary(lmBoth)
lmInter<-lm(Numeric~Year+Sex+Year*Sex, hunger)
summary(lmInter)
fit<-lm(y ~ x, out2)
plot(fit, which=1)
fitno<-lm(y ~ x, out2[-1,]))
fitno<-lm(y ~ x, out2[-1,])
plot(fitno, which=1)
coef(fit)-coef(fitno)
head(dfbeta(fit))
resno<- out2[1, "y"] - predict(fitno, out2[1,])
1-resid(fit)[1]/resno
head(hatvalues(fit))
sigma<-sum(res(fit))/df(fit)
sigma<-sum(residuals(fit))/df(fit)
sigma<-(sum(residuals(fit))/df(fit))^2
residuals(fit)
sigma <- sqrt(deviance(fit)/df.residual(fit))
rstd<-resid(fit)/sigma*sqrt(1-hatvalues(fit)
)
rstd<-resid(fit)/(sigma*sqrt(1-hatvalues(fit)))
head(cbind(rstd, rstandard(fit)))
plot(fit, which=3)
plot(fit, which=2)
sigma1<-sqrt(deviance(fitno)/df.residual(fitno))
resid(fit)[1]/(sigma*sqrt(1-hatvalues(fit)[1]))
resid(fit)[1]/(sigma1*sqrt(1-hatvalues(fit)[1]))
head(rstudent(fit))
dy<-predict(fitno, out2)-predict(fit, out2)
sum(dy)^2/2*sigma^2
sum(dy^2)/(2*sigma^2)
plot(fit, which=5)
library(MASS)
?shuttle
library(MASS)
data(shuttle)
fit<-glm(use~wind, data=shuttle, family = "logistic")
summary(fit)
library(MASS)
data(shuttle)
fit<-glm(use~wind, data=shuttle, family = "binomial")
summary(fit)
library(MASS)
data(shuttle)
shuttle$use2<- as.numeric(shuttle$use)
fit<-glm(use2~wind, data=shuttle, family = "binomial")
summary(fit)
#QUizz 4
#Question 1
library(MASS)
data(shuttle)
shuttle$use2<- as.numeric(shuttle$use)
fit<-glm(use2~factor(wind), data=shuttle, family = "binomial")
summary(fit)
#QUizz 4
#Question 1
library(MASS)
data(shuttle)
shuttle$use2<- as.numeric(shuttle$use)
fit<-glm(use2~factor(wind)-1, data=shuttle, family = "binomial")
summary(fit)
#QUizz 4
#Question 1
library(MASS)
data(shuttle)
shuttle2<-shuttle
shuttle2$use2<- as.numeric(shuttle$use)
fit<-glm(use2~factor(wind)-1, data=shuttle2, family = "binomial")
summary(fit)
#QUizz 4
#Question 1
library(MASS)
data(shuttle)
shuttle2<-shuttle
shuttle2$use2<- as.numeric(shuttle2$use=='auto')
fit<-glm(use2~factor(wind) - 1, data=shuttle2, family = "binomial")
summary(fit)
exp(coef(fit))
exp(coef(fit)[1])/exp(coed(fit)[2])
exp(coef(fit)[1])/exp(coef(fit)[2])
fit2<-glm(use2 ~ factor(wind) + factor(magn) - 1, family = binomial, data = shuttle2)
summary(fit2)$coef
exp(coef(fit2))
exp(coef(fit2)[1])/exp(coef(fit2)[2])
data("InsectSprays")
fit3<-glm(count~factor(spray), data=InsectSprays, family = poisson)
summary(fit3)
summary(fit3)
coef(fit3)[1,1]/coef(fit3)[2,1]
coef(fit3)[1]/coef(fit3)[2]
summary(fit3)$coef
exp(coef(fit3))
exp(coef(fit3)[1])/exp(coef(fit3)[2])
data("InsectSprays")
fit3<-glm(count~factor(spray)-1, data=InsectSprays, family = poisson)
summary(fit3)$coef
exp(coef(fit3))
exp(coef(fit3)[1])/exp(coef(fit3)[2])
log(10)
library(swirl)
swirl()
x1c<-simbias()
apply(x1c, 1, mean)
fit1<-lm(Fertility~., swiss)
fit1 <- lm(Fertility ~ Agriculture, swiss)
fit3<-lm(Fertility~Agriculture+Examination+Education, swiss)
anova(fit1, fit3)
deviance(fit3)
d<-deviance(fit3)/43
deviance(fit1)-deviance(fit3)/(45-43)
deviance(fit1)-deviance(fit3)/2
n <- (deviance(fit1) - deviance(fit3))/2
n/d
pf(n/d, 2,43 lower.tail=FALSE)
pf(n/d, 2,43, lower.tail=FALSE)
shapiro.test(fit3$residuals)
anova(fit1, fit3, fit5, fit6)
ravenData
md1<-glm(ravenWinNum~ravenScore, data=ravenData, family=binomial)
mdl<-glm(ravenWinNum ~ ravenScore, family=binomial, data=ravenData)
lodds<-predict(mdl, data.frame(ravenScore=c(0, 3, 6)))
exp(lodds)/(1+exp(lodds))
Summary(mdl)
summary(mdl)
exp(confint(mdl))
anova(mdl)
qchisq(0.95, 1)
var(rpois(1000, 50))
head(hits)
class(hits[,'date'])
as.integer(head(hits[,'date']))
mdl <-
glm(visits ~ date, poisson, hits)
summary(mdl)
confint(mdl, 'date')
exp(confint(mdl, 'date'))
which.max(hits[,'visits'])
hits[704,]
lambda<-mdl$fitted.values[704]
qpois(.95, lambda)
mdl2<-glm(visits~date, poisson,)
mdl2<-glm(visits~date, poisson, hits ,offset=log(visits+1))
mdl2<-glm(simplystats~date, poisson, hits ,offset=log(visits+1))
qpois(.95, mdl2$fitted.values[704])
library(AppliedPredictiveModeling)
data(AlzheimerDisease)
install.packages("AppliedPredictiveModeling")
library(AppliedPredictiveModeling)
data(AlzheimerDisease)
library(AppliedPredictiveModeling)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
trainIndex = createDataPartition(diagnosis,p=0.5,list=FALSE)
training = adData[trainIndex,]
testing = adData[-trainIndex,]
install.packages("caret")
library(AppliedPredictiveModeling)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
trainIndex = createDataPartition(diagnosis,p=0.5,list=FALSE)
training = adData[trainIndex,]
testing = adData[-trainIndex,]
library(caret)
library(AppliedPredictiveModeling)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
trainIndex = createDataPartition(diagnosis,p=0.5,list=FALSE)
training = adData[trainIndex,]
testing = adData[-trainIndex,]
library(AppliedPredictiveModeling)
data(concrete)
library(caret)
set.seed(1000)
inTrain = createDataPartition(mixtures$CompressiveStrength, p = 3/4)[[1]]
training = mixtures[ inTrain,]
testing = mixtures[-inTrain,]
install.packages("Hmisc")
head(training)
qplot(mixtures$CompressiveStrength)
plot(mixtures$CompressiveStrength)
plot(mixtures$CompressiveStrength, col=mixtures$Cement)
library(Hmisc)
mixtures$cementf<-cut2(mixtures$Cement)
plot(mixtures$CompressiveStrength, col=mixtures$cementf)
mixtures$BlastFurnaceSlagf<-cut2(mixtures$BlastFurnaceSlag)
plot(mixtures$CompressiveStrength, col=mixtures$BlastFurnaceSlagf)
mixtures$Agef<-cut2(mixtures$Age)
plot(mixtures$CompressiveStrength, col=mixtures$Agef)
mixtures$FlyAshf<-cut2(mixtures$FlyAsh)
plot(mixtures$CompressiveStrength, col=mixtures$FlyAshf)
corr(mixtures$FlyAsh, mixtures$CompressiveStrength)
cor(mixtures$FlyAsh, mixtures$CompressiveStrength)
cor(mixtures$Age, mixtures$CompressiveStrength)
hist(mixtures$Superplasticizer)
hist(log(mixtures$Superplasticizer)+1)
hist(log(mixtures$Superplasticizer))
library(caret)
library(AppliedPredictiveModeling)
set.seed(3433)data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]training = adData[ inTrain,]
testing = adData[-inTrain,]
plot(mixtures$CompressiveStrength, col=mixtures$cementf)
names <- colnames(concrete)
names <- names[-length(names)]
featurePlot(x = training[, names], y = training$CompressiveStrength, plot = "pairs")
index <- seq_along(1:nrow(training))
ggplot(data = training, aes(x = index, y = CompressiveStrength)) + geom_point() +
theme_bw()
names <- colnames(concrete)
names <- names[-length(names)]
featurePlot(x = training[, names], y = training$CompressiveStrength, plot = "pairs")
index <- seq_along(1:nrow(training))
ggplot(data = training, aes(x = index, y = CompressiveStrength)) + geom_point() +
theme_bw()
cutCS <- cut2(training$CompressiveStrength, g = 4)
summary(cutCS)
featurePlot(x = training[, names], y = cutCS, plot = "box")
hist((mixtures$Superplasticizer))
head(training)
library(caret)
library(AppliedPredictiveModeling)
set.seed(3433)data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]training = adData[ inTrain,]
testing = adData[-inTrain,]
IL_str <- grep("^IL", colnames(training), value = TRUE)
preProc <- preProcess(training[, IL_str], method = "pca", thresh = 0.8)
preProc$rotation
library(caret)
library(AppliedPredictiveModeling)
set.seed(3433)data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
training = adData[ inTrain,]
testing = adData[-inTrain,]
IL_str <- grep("^IL", colnames(training), value = TRUE)
preProc <- preProcess(training[, IL_str], method = "pca", thresh = 0.8)
preProc$rotation
hist(log(mixtures$Superplasticizer+1))
predict()
predict
dgamma
lm
colSums
install.packages("C:/Users/Yohann/Downloads/DDPQuiz3_1.0.zip", repos = NULL, type = "win.binary")
library(DDPQuiz3)
install.packages(DDPQuiz3_1.0)
library(DDPQuiz33_1.0)
setwd("D:/Documents/Data Science/Courses/Data Scientist Specialization (JOHN HOPKINS)/9. Data Products/project")
library(slidify)
author("BMI_App")
?echo
install_github('slidifyLibraries', 'ramnathv')
install.packages("devtools")
library(devtools)
install_github('slidifyLibraries', 'ramnathv')
publish(title = 'BMI', 'index.html', host = 'rpubs')
